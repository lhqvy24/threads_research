import os, time, csv, requests
from typing import Dict, Iterator, List, Optional
from dotenv import load_dotenv
import os

load_dotenv()  # Ä‘á»c file .env á»Ÿ cÃ¹ng thÆ° má»¥c

APP_ID  = os.getenv("APP_ID")
APP_SECRET = os.getenv("APP_SECRET")
REDIRECT_URI = os.getenv("REDIRECT_URI")
SCOPES = os.getenv("SCOPES")

THREADS_ACCESS_TOKEN = os.getenv("THREADS_ACCESS_TOKEN")
THREADS_USER_ID = os.getenv("THREADS_USER_ID")

BASE = "https://graph.threads.net/v1.0"

def _get(url: str, params: Optional[Dict]=None) -> Dict:
    params = params or {}
    params["access_token"] = THREADS_ACCESS_TOKEN
    r = requests.get(url, params=params, timeout=30)
    if not r.ok:
        raise RuntimeError(f"GET {url} failed {r.status_code}: {r.text}")
    return r.json()

def _paginate(url: str, params: Optional[Dict]=None) -> Iterator[Dict]:
    params = params or {}
    params["access_token"] = THREADS_ACCESS_TOKEN
    while True:
        r = requests.get(url, params=params, timeout=30)
        if not r.ok:
            raise RuntimeError(f"GET {url} failed {r.status_code}: {r.text}")
        payload = r.json()
        for item in payload.get("data", []):
            yield item
        next_url = payload.get("paging", {}).get("next")
        if not next_url:
            break
        # next_url Ä‘Ã£ cÃ³ Ä‘áº§y Ä‘á»§ query; Ä‘á»ƒ láº§n gá»i sau khÃ´ng gá»­i params ná»¯a
        url, params = next_url, {}
        # nháº¹ nhÃ ng tÃ´n trá»ng rate limit
        time.sleep(0.2)

def fetch_all_posts(fields: str) -> List[Dict]:
    url = f"{BASE}/{THREADS_USER_ID}/threads"
    return list(_paginate(url, {"fields": fields}))

def fetch_replies_for_post(media_id: str, fields: str) -> List[Dict]:
    url = f"{BASE}/{media_id}/replies"
    return list(_paginate(url, {"fields": fields}))

def save_csv(path: str, rows: List[Dict], headers: List[str]):
    with open(path, "w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=headers)
        w.writeheader()
        for row in rows:
            # chá»‰ ghi cÃ¡c cá»™t cÃ³ trong headers Ä‘á»ƒ trÃ¡nh key thá»«a
            w.writerow({k: row.get(k) for k in headers})

def main():
    if not THREADS_ACCESS_TOKEN or "PASTE_" in THREADS_ACCESS_TOKEN:
        raise SystemExit("âš ï¸  ChÆ°a Ä‘áº·t LONG_TOKEN. Sá»­a biáº¿n LONG_TOKEN á»Ÿ Ä‘áº§u file hoáº·c export THREADS_ACCESS_TOKEN trong shell.")
    if not THREADS_USER_ID or "PASTE_" in THREADS_USER_ID:
        raise SystemExit("âš ï¸  ChÆ°a Ä‘áº·t USER_ID. Sá»­a biáº¿n USER_ID á»Ÿ Ä‘áº§u file hoáº·c export THREADS_USER_ID trong shell.")

    # 1) Láº¥y toÃ n bá»™ posts cá»§a báº¡n
    post_fields = "id,caption,permalink,created_time,like_count,reply_count"
    posts = fetch_all_posts(post_fields)
    print(f"âœ… Fetched {len(posts)} posts")

    # LÆ°u posts.csv
    save_csv(
        "threads_posts.csv",
        posts,
        headers=["id", "caption", "permalink", "created_time", "like_count", "reply_count"],
    )
    print("ğŸ’¾ Saved posts -> threads_posts.csv")

    # 2) Láº¥y replies cho tá»«ng post
    reply_fields = "id,text,author,created_time,permalink"
    all_replies = []
    for p in posts:
        mid = p["id"]
        replies = fetch_replies_for_post(mid, reply_fields)
        for r in replies:
            r["media_id"] = mid  # gáº¯n post gá»‘c Ä‘á»ƒ join sau nÃ y
        all_replies.extend(replies)
        print(f"   â€¢ {mid}: {len(replies)} replies")
        time.sleep(0.2)  # nháº¹t rate

    # LÆ°u replies.csv
    save_csv(
        "threads_replies.csv",
        all_replies,
        headers=["id", "media_id", "text", "author", "created_time", "permalink"],
    )
    print(f"ğŸ’¾ Saved replies ({len(all_replies)}) -> threads_replies.csv")

if __name__ == "__main__":
    main()